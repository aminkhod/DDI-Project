{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/amin/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/amin/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/amin/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/amin/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/amin/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/amin/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/amin/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/amin/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/amin/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/amin/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/amin/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/amin/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import confusion_matrix_pretty_print\n",
    "from confusion_matrix_pretty_print import plot_confusion_matrix_from_data\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report,precision_score, auc, precision_recall_curve, roc_curve\n",
    "\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, Softmax, Dropout\n",
    "from keras import optimizers\n",
    "from keras import metrics as kmetr\n",
    "from keras.utils import plot_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTrain = pd.read_csv('../../tripleTrain42702.csv')\n",
    "dataTest = pd.read_csv('../../tripleTest42702.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Hold out Zeros\n",
    "\n",
    "# data = pd.read_csv('../../saved F(triple_cosineSNF).csv')\n",
    "\n",
    "# data[data.iloc[:,2]==0].to_csv('../../triple_cosineSNF(zeros).csv',index=False)\n",
    "# del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('../../saved F(triple_cosineSNF).csv')\n",
    "# data = data[data['2']!=0]\n",
    "# data.to_csv('triple_cosineSNF(-1and1).csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataTest = pd.read_csv('../../triple_cosineSNF(zeros).csv')\n",
    "\n",
    "# print(dataTest.shape,dataTrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = dataTrain.values[:,3:]\n",
    "# y_train = dataTrain.values[:,2].astype(int)\n",
    "# del dataTrain\n",
    "# # X_test = dataTest.values[:,3:]\n",
    "# # y_test = dataTest.values[:,2].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainNum = len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X_train = dataTrain.values[:,3:]\n",
    "# # y_train = dataTrain.values[:,2].astype(int)\n",
    "# # del dataTrain\n",
    "# X_test = dataTest.values[:,3:]\n",
    "# y_test = dataTest.values[:,2].astype(int)\n",
    "\n",
    "# testNum = len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1136"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16*71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X_train = dataTrain.values[:,3:]\n",
    "# # y_train = dataTrain.values[:,2].astype(int)\n",
    "# # del dataTrain\n",
    "# X_test = dataTest.values[:,3:]\n",
    "# y_test = dataTest.values[:,2].astype(int)\n",
    "\n",
    "# testNum = len(X_test)\n",
    "\n",
    "# #reshape data to fit model\n",
    "# # X_train = X_train.reshape(trainNum,16,71,1)\n",
    "# X_test = X_test.reshape(testNum,16,71,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X_train = dataTrain.values[:,3:]\n",
    "# # y_train = dataTrain.values[:,2].astype(int)\n",
    "# # del dataTrain\n",
    "# X_test = dataTest.values[:,3:]\n",
    "# y_test = dataTest.values[:,2].astype(int)\n",
    "\n",
    "# testNum = len(X_test)\n",
    "\n",
    "# #reshape data to fit model\n",
    "# # X_train = X_train.reshape(trainNum,16,71,1)\n",
    "# X_test = X_test.reshape(testNum,16,71,1)\n",
    "\n",
    "# # y_train = y_train + 1\n",
    "# y_test  = y_test + 1\n",
    "# # y_train = y_train / 2\n",
    "# y_test  = y_test / 2\n",
    "# # print(y_train[0], y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X_train = dataTrain.values[:,3:]\n",
    "# # y_train = dataTrain.values[:,2].astype(int)\n",
    "# # del dataTrain\n",
    "# X_test = dataTest.values[:,3:]\n",
    "# y_test = dataTest.values[:,2].astype(int)\n",
    "\n",
    "# testNum = len(X_test)\n",
    "\n",
    "# #reshape data to fit model\n",
    "# # X_train = X_train.reshape(trainNum,16,71,1)\n",
    "# X_test = X_test.reshape(testNum,16,71,1)\n",
    "\n",
    "# # y_train = y_train + 1\n",
    "# y_test  = y_test + 1\n",
    "# # y_train = y_train / 2\n",
    "# y_test  = y_test / 2\n",
    "# # print(y_train[0], y_test[0])\n",
    "\n",
    "# #one-hot encode target column\n",
    "# # y_train = to_categorical(y_train)\n",
    "# y_test = to_categorical(y_test)\n",
    "# # y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 0.] [1. 1. 1. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "X_train = dataTrain.values[:,3:]\n",
    "y_train = dataTrain.values[:,2].astype(int)\n",
    "del dataTrain\n",
    "trainNum = len(X_train)\n",
    "X_test = dataTest.values[:,3:]\n",
    "y_test = dataTest.values[:,2].astype(int)\n",
    "# del dataTest\n",
    "testNum = len(X_test)\n",
    "\n",
    "#reshape data to fit model\n",
    "X_train = X_train.reshape(trainNum,16,71,1)\n",
    "X_test = X_test.reshape(testNum,16,71,1)\n",
    "\n",
    "y_train = y_train + 1\n",
    "y_test  = y_test + 1\n",
    "y_train = y_train / 2\n",
    "y_test  = y_test / 2\n",
    "print(y_train[0:5], y_test[0:5])\n",
    "\n",
    "#one-hot encode target column\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "# y_test[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]] [[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0:5], y_test[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 13, 68, 128)       2176      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 10, 65, 32)        65568     \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 7, 62, 8)          4104      \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 3472)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                222272    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 295,194\n",
      "Trainable params: 295,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# #create model\n",
    "# model = Sequential()\n",
    "# #add model layers\n",
    "# # kernel_initializer='uniform',\n",
    "# # kernel_initializer='uniform',\n",
    "# # kernel_initializer='uniform',\n",
    "# # kernel_initializer='uniform',\n",
    "# model.add(Conv2D(128, kernel_size=4, activation='relu', input_shape=(16,71,1)))\n",
    "# # model.add(Conv2D(64, kernel_size=2, activation='relu'))\n",
    "\n",
    "# model.add(Conv2D(32, kernel_size=4, activation='relu'))\n",
    "# # model.add(Conv2D(16, kernel_size=2, activation='relu'))\n",
    "# model.add(Conv2D(8, kernel_size=4, activation='relu'))\n",
    "# model.add(Flatten())\n",
    "# # model.add(Dense( 64, activation='relu'))\n",
    "# model.add(Dense( 32, activation='relu'))\n",
    "# # model.add(Dropout(0.2))\n",
    "# model.add(Dropout(0.4))\n",
    "# # model.add(Dense( 16, activation='relu'))\n",
    "# model.add(Dense( 8, activation='relu'))\n",
    "# model.add(Dropout(0.4))\n",
    "# model.add(Dense( 2, activation='sigmoid'))\n",
    "# # model.add(Softmax(128))\n",
    "# model.summary()\n",
    "\n",
    "#create model\n",
    "model = Sequential()\n",
    "#add model layers\n",
    "# kernel_initializer='uniform',\n",
    "# kernel_initializer='uniform',\n",
    "# kernel_initializer='uniform',\n",
    "# kernel_initializer='uniform',\n",
    "model.add(Conv2D(128, kernel_size=4, activation='relu', input_shape=(16,71,1)))\n",
    "# model.add(Conv2D(64, kernel_size=2, activation='relu'))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=4, activation='relu'))\n",
    "# model.add(Conv2D(16, kernel_size=2, activation='relu'))\n",
    "model.add(Conv2D(8, kernel_size=4, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense( 64, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense( 16, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "# model.add(Softmax(128))\n",
    "model.summary()\n",
    "\n",
    "#compile model using accuracy to measure model performance\n",
    "\n",
    "\n",
    "adam = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999)\n",
    "# model.compile(loss='hinge', optimizer=adam, metrics=[kmetr.categorical_accuracy])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) ## Minist\n",
    "\n",
    "### Load the model's saved weights.\n",
    "# model.load_weights('cnn43110(1and-1)_rivised_8_epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "###plotting model\n",
    "# plot_model(model,show_shapes = True, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38800 samples, validate on 3902 samples\n",
      "Epoch 1/15\n",
      "38800/38800 [==============================] - 195s 5ms/step - loss: 0.4015 - acc: 0.8259 - val_loss: 0.2956 - val_acc: 0.8688\n",
      "Epoch 2/15\n",
      "38800/38800 [==============================] - 198s 5ms/step - loss: 0.2328 - acc: 0.9015 - val_loss: 0.2235 - val_acc: 0.9147\n",
      "Epoch 3/15\n",
      "38800/38800 [==============================] - 297s 8ms/step - loss: 0.1678 - acc: 0.9330 - val_loss: 0.1986 - val_acc: 0.9267\n",
      "Epoch 4/15\n",
      "38800/38800 [==============================] - 383s 10ms/step - loss: 0.1322 - acc: 0.9467 - val_loss: 0.1837 - val_acc: 0.9362\n",
      "Epoch 5/15\n",
      "38800/38800 [==============================] - 380s 10ms/step - loss: 0.1077 - acc: 0.9552 - val_loss: 0.1865 - val_acc: 0.9395\n",
      "Epoch 6/15\n",
      "38800/38800 [==============================] - 383s 10ms/step - loss: 0.0931 - acc: 0.9606 - val_loss: 0.1729 - val_acc: 0.9436\n",
      "Epoch 7/15\n",
      "38800/38800 [==============================] - 382s 10ms/step - loss: 0.0778 - acc: 0.9661 - val_loss: 0.1669 - val_acc: 0.9536\n",
      "Epoch 8/15\n",
      "38800/38800 [==============================] - 366s 9ms/step - loss: 0.0696 - acc: 0.9689 - val_loss: 0.1852 - val_acc: 0.9487\n",
      "Epoch 9/15\n",
      "38800/38800 [==============================] - 201s 5ms/step - loss: nan - acc: 0.4182 - val_loss: nan - val_acc: 0.2178\n",
      "Epoch 10/15\n",
      "38800/38800 [==============================] - 200s 5ms/step - loss: nan - acc: 0.2149 - val_loss: nan - val_acc: 0.2178\n",
      "Epoch 11/15\n",
      "38800/38800 [==============================] - 201s 5ms/step - loss: nan - acc: 0.2149 - val_loss: nan - val_acc: 0.2178\n",
      "Epoch 12/15\n",
      "33824/38800 [=========================>....] - ETA: 26s - loss: nan - acc: 0.2146"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-f385d6fef4d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# #### train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# history = model.fit(X_train, y_train, epochs=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# #### train the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=15)\n",
    "# history = model.fit(X_train, y_train, epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Saveing the Model\n",
    "model.save_weights('cnnSelection42702(1and-1)_15_epoch.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predit = model.predict(X_test)\n",
    "#actual results for first 4 images in test set\n",
    "print(predit[:4])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "\n",
    "prec, rec, thr = precision_recall_curve(y_test[:,0], predit[:,0])\n",
    "aupr_val = auc(rec, prec)\n",
    "fpr, tpr, thr = roc_curve(y_test[:,0], predit[:,0])\n",
    "auc_val = auc(fpr, tpr)\n",
    "print(aupr_val,auc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(list(range(1,16)),model.history.history['acc'])\n",
    "plt.plot(list(range(1,16)),model.history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(list(range(1,16)),model.history.history['loss'])\n",
    "plt.plot(list(range(1,16)),model.history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # predit\n",
    "# predit[:,0].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predicts = []\n",
    "for a,b in predit:\n",
    "    if a >=b:\n",
    "        predicts.append(0)\n",
    "    else:\n",
    "        predicts.append(1)\n",
    "len(predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degrassive 166 enhancive 2454 zeros 266\n",
      "Epoch4: degrassive 224 enhancive 2939 zeros 40\n",
      "Epoch05: degrassive 280 enhancive 2823 zeros 39\n",
      "Epoch06: degrassive 233 enhancive 2879 zeros 79\n",
      "Epoch07: degrassive 203 enhancive 2926 zeros 134\n",
      "Epoch08: degrassive 224 enhancive 2895 zeros 180\n",
      "Epoch09: degrassive 191 enhancive 2856 zeros 191\n",
      "Epoch10: degrassive 189 enhancive 2821 zeros 246\n",
      "Epoch11: degrassive 164 enhancive 2581 zeros 235\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicts1 = []\n",
    "e = d = z = 0\n",
    "\n",
    "for a,b in predit:\n",
    "    if a >=0.90:\n",
    "        predicts1.append(0)\n",
    "        d += 1\n",
    "    elif b>=0.95:\n",
    "        predicts1.append(2)\n",
    "        e += 1\n",
    "    elif a<=0.05 and b<=0.1:\n",
    "        predicts1.append(1)\n",
    "        z += 1\n",
    "print('degrassive', d, 'enhancive', e, 'zeros', z)\n",
    "print(\"\"\"\n",
    "Epoch04: degrassive 224 enhancive 2939 zeros 40\n",
    "Epoch05: degrassive 280 enhancive 2823 zeros 39\n",
    "Epoch06: degrassive 233 enhancive 2879 zeros 79\n",
    "Epoch07: degrassive 203 enhancive 2926 zeros 134\n",
    "Epoch08: degrassive 224 enhancive 2895 zeros 180\n",
    "Epoch09: degrassive 191 enhancive 2856 zeros 191\n",
    "Epoch10: degrassive 189 enhancive 2821 zeros 246\n",
    "Epoch11: degrassive 164 enhancive 2581 zeros 235\n",
    "Epoch12: degrassive 166 enhancive 2454 zeros 266\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max(list((dataTest.values[:,2]+1)/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "cm = confusion_matrix(list(predicts), list((dataTest.values[:,2]+1)/2))\n",
    "print(cm)\n",
    "\n",
    "CR = classification_report(list((dataTest.values[:,2]+1)/2),list(predicts))\n",
    "print(CR)\n",
    "print(145/4702)\n",
    "# i=0\n",
    "# for j in list(data.values[9500:,2]+1):\n",
    "#     if j==1:\n",
    "#         i +=1\n",
    "# print(i)\n",
    "\n",
    "# plt.show()\n",
    "plot_confusion_matrix_from_data(list((dataTest.values[:,2]+1)/2), list(predicts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(predit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(predit).plot.density()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(predit).iloc[:,0].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(predit).iloc[:,1].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(16, 8)\n",
    "\n",
    "# matplotlib histogram\n",
    "# plt.hist(pd.DataFrame(predit).iloc[:,1], color = 'blue', edgecolor = 'black',\n",
    "#          bins = int(200))\n",
    "\n",
    "# seaborn histogram\n",
    "sns.distplot(pd.DataFrame(predit).iloc[:,1], hist=True, kde=False, \n",
    "             bins=int(100), color = 'blue',\n",
    "             hist_kws={'edgecolor':'black'})\n",
    "\n",
    "# sns.distplot(pd.DataFrame(predit).iloc[:,0], hist=True, kde=True, \n",
    "#              bins=int(200), color = 'darkblue', \n",
    "#              hist_kws={'edgecolor':'black'},\n",
    "#              kde_kws={'linewidth': 4})\n",
    "# Add labels\n",
    "plt.title('frequency Histogram of Drugs')\n",
    "plt.xlabel('Enhancive drugs Probability')\n",
    "plt.ylabel('frequency distribution')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(16,8)\n",
    "\n",
    "# matplotlib histogram\n",
    "# plt.hist(pd.DataFrame(predit).iloc[:,1], color = 'blue', edgecolor = 'black',\n",
    "#          bins = int(200))\n",
    "\n",
    "# seaborn histogram\n",
    "\n",
    "sns.distplot(pd.DataFrame(predit).iloc[:,0], hist=True, kde=False, \n",
    "             bins=int(100), color = 'red',\n",
    "             hist_kws={'edgecolor':'black'})\n",
    "# sns.distplot(pd.DataFrame(predit).iloc[:,0], hist=True, kde=True, \n",
    "#              bins=int(200), color = 'darkblue', \n",
    "#              hist_kws={'edgecolor':'black'},\n",
    "#              kde_kws={'linewidth': 4})\n",
    "# Add labels\n",
    "plt.title('frequency Histogram of Drugs')\n",
    "plt.xlabel('Degressive drugs Probability')\n",
    "plt.ylabel('frequency distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(16,8)\n",
    "\n",
    "# matplotlib histogram\n",
    "# plt.hist(pd.DataFrame(predit).iloc[:,1], color = 'blue', edgecolor = 'black',\n",
    "#          bins = int(200))\n",
    "\n",
    "# seaborn histogram\n",
    "sns.distplot(pd.DataFrame(predit).iloc[:,1], hist=True, kde=False, \n",
    "             bins=int(100), color = 'blue',\n",
    "             hist_kws={'edgecolor':'black'})\n",
    "\n",
    "sns.distplot(pd.DataFrame(predit).iloc[:,0], hist=True, kde=False, \n",
    "             bins=int(100), color = 'red',\n",
    "             hist_kws={'edgecolor':'black'})\n",
    "# sns.distplot(pd.DataFrame(predit).iloc[:,0], hist=True, kde=True, \n",
    "#              bins=int(200), color = 'darkblue', \n",
    "#              hist_kws={'edgecolor':'black'},\n",
    "#              kde_kws={'linewidth': 4})\n",
    "# Add labels\n",
    "plt.title('frequency Histogram of Drugs')\n",
    "plt.xlabel('both of Degressive and Enhancive drugs Probability')\n",
    "plt.ylabel('frequency distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
