{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import confusion_matrix_pretty_print\n",
    "# from confusion_matrix_pretty_print import plot_confusion_matrix_from_data\n",
    "\n",
    "# from sklearn.metrics import confusion_matrix,classification_report,precision_score,auc,precision_recall_curve,roc_curve\n",
    "\n",
    "# import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, Softmax, Dropout\n",
    "from keras import optimizers\n",
    "# from keras import metrics as kmetr\n",
    "# from keras.utils import plot_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1136"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16*71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 13, 68, 128)       2176      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 10, 65, 32)        65568     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 62, 8)          4104      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3472)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                222272    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 295194 (1.13 MB)\n",
      "Trainable params: 295194 (1.13 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "# #create model\n",
    "# model = Sequential()\n",
    "# #add model layers\n",
    "# # kernel_initializer='uniform',\n",
    "# # kernel_initializer='uniform',\n",
    "# # kernel_initializer='uniform',\n",
    "# # kernel_initializer='uniform',\n",
    "# model.add(Conv2D(128, kernel_size=4, activation='relu', input_shape=(16,71,1)))\n",
    "# # model.add(Conv2D(64, kernel_size=2, activation='relu'))\n",
    "\n",
    "# model.add(Conv2D(32, kernel_size=4, activation='relu'))\n",
    "# # model.add(Conv2D(16, kernel_size=2, activation='relu'))\n",
    "# model.add(Conv2D(8, kernel_size=4, activation='relu'))\n",
    "# model.add(Flatten())\n",
    "# # model.add(Dense( 64, activation='relu'))\n",
    "# model.add(Dense( 32, activation='relu'))\n",
    "# # model.add(Dropout(0.2))\n",
    "# model.add(Dropout(0.4))\n",
    "# # model.add(Dense( 16, activation='relu'))\n",
    "# model.add(Dense( 8, activation='relu'))\n",
    "# model.add(Dropout(0.4))\n",
    "# model.add(Dense( 2, activation='sigmoid'))\n",
    "# # model.add(Softmax(128))\n",
    "# model.summary()\n",
    "\n",
    "#create model\n",
    "model = Sequential()\n",
    "#add model layers\n",
    "# kernel_initializer='uniform',\n",
    "# kernel_initializer='uniform',\n",
    "# kernel_initializer='uniform',\n",
    "# kernel_initializer='uniform',\n",
    "model.add(Conv2D(128, kernel_size=4, activation='relu', input_shape=(16,71,1)))\n",
    "# model.add(Conv2D(64, kernel_size=2, activation='relu'))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=4, activation='relu'))\n",
    "# model.add(Conv2D(16, kernel_size=2, activation='relu'))\n",
    "model.add(Conv2D(8, kernel_size=4, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense( 64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense( 16, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "# model.add(Softmax(128))\n",
    "model.summary()\n",
    "\n",
    "#compile model using accuracy to measure model performance\n",
    "\n",
    "\n",
    "adam = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999)\n",
    "# model.compile(loss='hinge', optimizer=adam, metrics=[kmetr.categorical_accuracy])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) ## Minist\n",
    "\n",
    "### Load the model's saved weights.\n",
    "model.load_weights('Weight/CNN on triple DDI-Train on 42702_6_epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279354"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((568*568-568)-42702)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46559.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "279354/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type float).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 35\u001b[0m\n\u001b[0;32m     20\u001b[0m     X_test \u001b[38;5;241m=\u001b[39m X_test\u001b[38;5;241m.\u001b[39mreshape(testNum, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m71\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# y_train = y_train + 1\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m#     y_test  = y_test + 1\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# y_train = y_train / 2\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     33\u001b[0m \n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m#predict first 4 images in the test set\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m     predit \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m     X_test \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     38\u001b[0m     pd\u001b[38;5;241m.\u001b[39mDataFrame(predit)\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict_(-1 and +1 model)\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(k)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:98\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     96\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m     97\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type float)."
     ]
    }
   ],
   "source": [
    "zeroIndexes = []\n",
    "predicts = []\n",
    "e = d = z = 0\n",
    "zeroIndexes = []\n",
    "DegIndexes = []\n",
    "EnhIndexes = []\n",
    "k = 0\n",
    "for i in range(0,279354,46559):\n",
    "    j = i + 46491\n",
    "    # X_train = dataTrain.values[:,3:]\n",
    "    # y_train = dataTrain.values[:,2].astype(int)\n",
    "    # del dataTrain\n",
    "    X_test = pd.read_csv('../../triple_cosineSNF(zeros).csv').values[i:j, 3:]\n",
    "#     y_test = dataTest.values[i:j,2].astype(int)\n",
    "\n",
    "    testNum = len(X_test)\n",
    "\n",
    "    #reshape data to fit model\n",
    "    # X_train = X_train.reshape(trainNum,16,71,1)\n",
    "    X_test = X_test.reshape(testNum, 16, 71, 1).astype('float32')\n",
    "\n",
    "    # y_train = y_train + 1\n",
    "#     y_test  = y_test + 1\n",
    "    # y_train = y_train / 2\n",
    "#     y_test  = y_test / 2\n",
    "    # print(y_train[0], y_test[0])\n",
    "\n",
    "    #one-hot encode target column\n",
    "    # y_train = to_categorical(y_train)\n",
    "#     y_test = to_categorical(y_test)\n",
    "    # y_test[0]\n",
    "\n",
    "\n",
    "    #predict first 4 images in the test set\n",
    "    predit = model.predict(X_test)\n",
    "    X_test = []\n",
    "    \n",
    "    pd.DataFrame(predit).to_csv('predict_(-1 and +1 model)' + str(k)+'.csv', index=False)\n",
    "#     predit\n",
    "    k += 1\n",
    "    f = 0\n",
    "    for a,b in predit:\n",
    "        if a >=0.95:\n",
    "            predicts.append(0)\n",
    "            d += 1\n",
    "            DegIndexes.append(i + f)\n",
    "            f += 1\n",
    "            \n",
    "        elif b>=0.95:\n",
    "            predicts.append(2)\n",
    "            e += 1\n",
    "            EnhIndexes.append(i + f)\n",
    "            f += 1\n",
    "            \n",
    "        elif b <=0.4 and a <= 0.4:\n",
    "            predicts.append(1)\n",
    "            z += 1\n",
    "            zeroIndexes.append(i + f)\n",
    "            f += 1\n",
    "            \n",
    "#     predit = []\n",
    "    print('degrassive', d, 'enhancive', e, 'zeros', z)\n",
    "    pd.DataFrame(EnhIndexes).to_csv('enhansive indexes_(-1 and +1 model)' + str(k-1) +'.csv', index=False)\n",
    "    EnhIndexes = []\n",
    "    \n",
    "    pd.DataFrame(DegIndexes).to_csv('Degrassive indexes_(-1 and +1 model)' + str(k-1) +'.csv', index=False)\n",
    "    DegIndexes = []\n",
    " \n",
    "    pd.DataFrame(zeroIndexes).to_csv('zero indexes_(-1 and +1 model)' + str(k-1) +'.csv', index=False)\n",
    "    zeroIndexes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(predit).plot.density()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(predit).iloc[:,0].plot.density()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(predit).iloc[:,1].plot.density()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(16, 8)\n",
    "\n",
    "# matplotlib histogram\n",
    "# plt.hist(pd.DataFrame(predit).iloc[:,1], color = 'blue', edgecolor = 'black',\n",
    "#          bins = int(200))\n",
    "\n",
    "# seaborn histogram\n",
    "sns.distplot(pd.DataFrame(predit).iloc[:,1], hist=True, kde=False, \n",
    "             bins=int(100), color = 'blue',\n",
    "             hist_kws={'edgecolor':'black'})\n",
    "\n",
    "# sns.distplot(pd.DataFrame(predit).iloc[:,0], hist=True, kde=True, \n",
    "#              bins=int(200), color = 'darkblue', \n",
    "#              hist_kws={'edgecolor':'black'},\n",
    "#              kde_kws={'linewidth': 4})\n",
    "# Add labels\n",
    "plt.title('frequency Histogram of Zero Drugs')\n",
    "plt.xlabel('Enhancive drugs Probability')\n",
    "plt.ylabel('frequency distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(16,8)\n",
    "\n",
    "# matplotlib histogram\n",
    "# plt.hist(pd.DataFrame(predit).iloc[:,1], color = 'blue', edgecolor = 'black',\n",
    "#          bins = int(200))\n",
    "\n",
    "# seaborn histogram\n",
    "\n",
    "sns.distplot(pd.DataFrame(predit).iloc[:,0], hist=True, kde=False, \n",
    "             bins=int(100), color = 'red',\n",
    "             hist_kws={'edgecolor':'black'})\n",
    "# sns.distplot(pd.DataFrame(predit).iloc[:,0], hist=True, kde=True, \n",
    "#              bins=int(200), color = 'darkblue', \n",
    "#              hist_kws={'edgecolor':'black'},\n",
    "#              kde_kws={'linewidth': 4})\n",
    "# Add labels\n",
    "plt.title('frequency Histogram of Degrassive Drugs')\n",
    "plt.xlabel('Degressive drugs Probability')\n",
    "plt.ylabel('frequency distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(16,8)\n",
    "\n",
    "# matplotlib histogram\n",
    "# plt.hist(pd.DataFrame(predit).iloc[:,1], color = 'blue', edgecolor = 'black',\n",
    "#          bins = int(200))\n",
    "\n",
    "# seaborn histogram\n",
    "sns.distplot(pd.DataFrame(predit).iloc[:,1], hist=True, kde=False, \n",
    "             bins=int(100), color = 'blue',\n",
    "             hist_kws={'edgecolor':'black'})\n",
    "\n",
    "sns.distplot(pd.DataFrame(predit).iloc[:,0], hist=True, kde=False, \n",
    "             bins=int(100), color = 'red',\n",
    "             hist_kws={'edgecolor':'black'})\n",
    "# sns.distplot(pd.DataFrame(predit).iloc[:,2], hist=True, kde=False, \n",
    "#              bins=int(100), color = 'green',\n",
    "#              hist_kws={'edgecolor':'black'})\n",
    "# sns.distplot(pd.DataFrame(predit).iloc[:,0], hist=True, kde=True, \n",
    "#              bins=int(200), color = 'darkblue', \n",
    "#              hist_kws={'edgecolor':'black'},\n",
    "#              kde_kws={'linewidth': 4})\n",
    "# Add labels\n",
    "plt.title('frequency Histogram of Drugs')\n",
    "plt.xlabel('both of Degressive and Enhancive drugs Probability')\n",
    "plt.ylabel('frequency distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
