\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{wienkers2005predicting}
\citation{law2014drugbank}
\citation{leape1995systems,businaro2013we,karbownik2017pharmacokinetic,mulroy2017giant}
\citation{zhao2011prediction}
\citation{veith2009comprehensive}
\citation{huang2007drug}
\citation{zhang2015label}
\newcplabel{^_1}{1}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\citation{wisniowska2016role,zhou2016simulation}
\citation{zhang2015label}
\citation{bui2014novel,zhang2016leveraging}
\citation{yamanishi2008prediction}
\citation{vilar2014similarity}
\citation{zhang2015label}
\citation{cheng2014machine}
\citation{pahikkala2015toward}
\citation{vilar2014similarity}
\citation{luo2014ddi}
\citation{cheng2014machine}
\citation{zhang2015label,shi2017predicting}
\citation{liu2016dependency}
\citation{ryu2018deep}
\citation{wang2014similarity}
\citation{olayan2018ddr,tian2017constructing,kim2016understanding}
\citation{wang2016predicting}
\citation{huang2009effect,fu2017deep,pan2016ipminer}
\citation{koch1981serum}
\citation{yu2018predicting}
\@writefile{toc}{\contentsline {section}{\numberline {2}Methods}{3}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {{2.1}}Dataset and features}{3}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {{2.2}}Problem formulation}{3}{subsection.2.2}\protected@file@percent }
\citation{zhang2016drug,zhang2018manifold}
\citation{wang2014similarity}
\citation{wang2014similarity}
\citation{SNFPy2020}
\@writefile{toc}{\contentsline {subsection}{\numberline {{2.3}}Data preparing}{4}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {{{2.3}.1}}Similarity matrix calculation}{4}{subsubsection.2.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {{{2.3}.2}}Integration drug similarity matrices}{4}{subsubsection.2.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces SNF processes \cite  {wang2014similarity}: A detailed example of SNF steps. (a) An example representation of chemical structure feature and off-label side effect feature for the same set of drugs. (b) Drug-drug similarity matrices for each feature type. (c) Drug-drug similarity networks, equivalent to the drug-drug data. Nodes represent drugs, and edges represent drug pairwise similarities. (d) Network fusion by SNF iteratively updates each of the networks with information from the other networks, making them more similar with each step. (e) The iterative network fusion results in convergence to the final fused network. Edge color indicates which data type has contributed to the given similarity. \relax }}{5}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{SNF}{{1}{5}{SNF processes \cite {wang2014similarity}: A detailed example of SNF steps. (a) An example representation of chemical structure feature and off-label side effect feature for the same set of drugs. (b) Drug-drug similarity matrices for each feature type. (c) Drug-drug similarity networks, equivalent to the drug-drug data. Nodes represent drugs, and edges represent drug pairwise similarities. (d) Network fusion by SNF iteratively updates each of the networks with information from the other networks, making them more similar with each step. (e) The iterative network fusion results in convergence to the final fused network. Edge color indicates which data type has contributed to the given similarity. \relax }{figure.caption.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {{{2.3}.3}}Input matrix format}{5}{subsubsection.2.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Matrix header of B\relax }}{5}{figure.caption.2}\protected@file@percent }
\newlabel{BMatHeader}{{2}{5}{Matrix header of B\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{2.4}}Devising of Recommender System}{5}{subsection.2.4}\protected@file@percent }
\citation{nair2010rectified}
\citation{hinton2012deep}
\citation{srivastava2014dropout}
\@writefile{toc}{\contentsline {subsection}{\numberline {{2.5}}Selecting and training model on known interactions}{6}{subsection.2.5}\protected@file@percent }
\newlabel{Selecting model}{{{2.6}}{6}{Selecting model}{subsection.2.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{2.6}}Selecting model}{6}{subsection.2.6}\protected@file@percent }
\citation{abadi2016tensorflow}
\citation{chollet2015keras}
\citation{ghosal1997your,toda2012research,seen20121}
\citation{kingma2014adam}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The arrangement of the neural network layers for detecting possible zeros\relax }}{7}{figure.caption.3}\protected@file@percent }
\newlabel{CNNModel}{{3}{7}{The arrangement of the neural network layers for detecting possible zeros\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Learnable parameters of two-class Neural Networks\relax }}{8}{figure.caption.4}\protected@file@percent }
\newlabel{paramNumber1}{{4}{8}{Learnable parameters of two-class Neural Networks\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces probability density distribution diagram of Degressive and enhancive. In this figure, 0 is the same as the $-1$label, and 1 is the same as $+1$.\relax }}{9}{figure.caption.5}\protected@file@percent }
\newlabel{DDIProbHist}{{5}{9}{probability density distribution diagram of Degressive and enhancive. In this figure, 0 is the same as the $-1$label, and 1 is the same as $+1$.\relax }{figure.caption.5}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Model selection suducode\relax }}{9}{algorithm.1}\protected@file@percent }
\newlabel{modelSelectionSuducode}{{1}{9}{Model selection suducode\relax }{algorithm.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{2.7}}Selecting and training model on known and unknown interactions}{9}{subsection.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {{2.8}}Selecting final model}{10}{subsection.2.8}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Final model selection(SNF-CNN) suducode\relax }}{10}{algorithm.2}\protected@file@percent }
\newlabel{SNFCNNSuducode}{{2}{10}{Final model selection(SNF-CNN) suducode\relax }{algorithm.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Result and discussion}{10}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {{3.1}}Assessment}{10}{subsection.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Arrangement of neural network layers SNF-CNN Predict triple-class interaction. Non-interaction (0), degressive interaction (-1) and enhancive interaction (+1)\relax }}{11}{figure.caption.7}\protected@file@percent }
\newlabel{Triple_model}{{6}{11}{Arrangement of neural network layers SNF-CNN Predict triple-class interaction. Non-interaction (0), degressive interaction (-1) and enhancive interaction (+1)\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {{{3.1}.1}}First case: 10-fold CV without unknown interactions}{11}{subsubsection.3.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces \textbf  {Accuracy and loss function for the binary model:} The right figure shows the model's accuracy on training and validation data during 15 epochs, and the left figure shows the loss function values at different epochs.\relax }}{12}{figure.caption.8}\protected@file@percent }
\newlabel{ModelSelection}{{7}{12}{\textbf {Accuracy and loss function for the binary model:} The right figure shows the model's accuracy on training and validation data during 15 epochs, and the left figure shows the loss function values at different epochs.\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {{{3.1}.2}}Second case: 10-fold CV with unknown interactions}{12}{subsubsection.3.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces \textbf  {Accuracy and loss function diagrams for the triple model:} The right figure shows the accuracy of the model on training and validation data during 16 epochs, and the left figure shows the loss function values at different epochs.\relax }}{12}{figure.caption.9}\protected@file@percent }
\newlabel{lastTripleModel}{{8}{12}{\textbf {Accuracy and loss function diagrams for the triple model:} The right figure shows the accuracy of the model on training and validation data during 16 epochs, and the left figure shows the loss function values at different epochs.\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Evaluation criteria}{13}{section.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces The confusion matrix and relevant evaluation index.True Positive (TP): The number of residues classified as interacting correctly, False Positive (FP): The number of residues classified as interacting correctly incorrectly, False Negative (FN): The number of residues classified as non-interacting incorrectly, True Negative (TN): The number of residues classified as non-interacting correctly.\relax }}{13}{table.caption.10}\protected@file@percent }
\newlabel{Table1}{{1}{13}{The confusion matrix and relevant evaluation index.True Positive (TP): The number of residues classified as interacting correctly, False Positive (FP): The number of residues classified as interacting correctly incorrectly, False Negative (FN): The number of residues classified as non-interacting incorrectly, True Negative (TN): The number of residues classified as non-interacting correctly.\relax }{table.caption.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Comparison of results}{14}{section.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Interaction type classification report\relax }}{14}{table.caption.11}\protected@file@percent }
\newlabel{classificatonReport}{{2}{14}{Interaction type classification report\relax }{table.caption.11}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Three-Classes interaction classification report\relax }}{14}{table.caption.12}\protected@file@percent }
\newlabel{TripleclassificatonReport}{{3}{14}{Three-Classes interaction classification report\relax }{table.caption.12}{}}
\citation{shi2019detecting}
\citation{yu2018predicting}
\citation{shi2018tmfuf}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Results of SNF-CNN algorithm in predicting three-classes based on AUC and AUPR criteria and their confidence interval\relax }}{15}{table.caption.13}\protected@file@percent }
\newlabel{SNF-CNNresult}{{4}{15}{Results of SNF-CNN algorithm in predicting three-classes based on AUC and AUPR criteria and their confidence interval\relax }{table.caption.13}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Comparison of the results of three-classes prediction algorithms based on criteria AUC and AUPR\relax }}{15}{table.caption.14}\protected@file@percent }
\newlabel{AUCAUPR}{{5}{15}{Comparison of the results of three-classes prediction algorithms based on criteria AUC and AUPR\relax }{table.caption.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusions}{15}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {{6.1}}Figures}{16}{subsection.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {{{6.1}.1}}Permission to Reuse and Copyright}{16}{subsubsection.6.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {{6.2}}Tables}{17}{subsection.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Nomenclature}{17}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {{7.1}}Resource Identification Initiative}{17}{subsection.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {{7.2}}Life Science Identifiers}{17}{subsection.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8}Additional Requirements}{17}{section.8}\protected@file@percent }
\bibstyle{frontiersinSCNS_ENG_HUMS}
\bibdata{test}
\bibcite{abadi2016tensorflow}{{1}{2016}{{Abadi et~al.}}{{Abadi, Barham, Chen, Chen, Davis, Dean et~al.}}}
\bibcite{bui2014novel}{{2}{2014}{{Bui et~al.}}{{Bui, Sloot, Van~Mulligen, and Kors}}}
\bibcite{businaro2013we}{{3}{2013}{{Businaro}}{{}}}
\bibcite{cheng2014machine}{{4}{2014}{{Cheng and Zhao}}{{}}}
\bibcite{chollet2015keras}{{5}{2015}{{Chollet et~al.}}{{}}}
\bibcite{fu2017deep}{{6}{2017}{{Fu and Peng}}{{}}}
\bibcite{ghosal1997your}{{7}{1997}{{Ghosal et~al.}}{{Ghosal, Edithal, Ekbal, Bhattacharyya, Chivukula, and Tsatsaronis}}}
\bibcite{hinton2012deep}{{8}{2012}{{Hinton et~al.}}{{Hinton, Deng, Yu, Dahl, Mohamed, Jaitly et~al.}}}
\bibcite{huang2009effect}{{9}{2009}{{Huang et~al.}}{{Huang, Hu, Huang, Li, Yuan, Pan et~al.}}}
\bibcite{huang2007drug}{{10}{2007}{{Huang et~al.}}{{Huang, Temple, Throckmorton, and Lesko}}}
\bibcite{karbownik2017pharmacokinetic}{{11}{2017}{{Karbownik et~al.}}{{Karbownik, Sza{\l }ek, Soba{\'n}ska, Grabowski, Wolc, and Grze{\'s}kowiak}}}
\bibcite{kim2016understanding}{{12}{2016}{{Kim et~al.}}{{Kim, Cho, and Przytycka}}}
\bibcite{kingma2014adam}{{13}{2014}{{Kingma and Ba}}{{}}}
\bibcite{koch1981serum}{{14}{1981}{{Koch-Weser}}{{}}}
\bibcite{law2014drugbank}{{15}{2014}{{Law et~al.}}{{Law, Knox, Djoumbou, Jewison, Guo, Liu et~al.}}}
\bibcite{leape1995systems}{{16}{1995}{{Leape et~al.}}{{Leape, Bates, Cullen, Cooper, Demonaco, Gallivan et~al.}}}
\bibcite{liu2016dependency}{{17}{2016}{{Liu et~al.}}{{Liu, Chen, Chen, and Tang}}}
\bibcite{luo2014ddi}{{18}{2014}{{Luo et~al.}}{{Luo, Zhang, Huang, Huang, Kao, Shi et~al.}}}
\bibcite{mulroy2017giant}{{19}{2017}{{Mulroy et~al.}}{{Mulroy, Highton, and Jordan}}}
\bibcite{nair2010rectified}{{20}{2010}{{Nair and Hinton}}{{}}}
\bibcite{olayan2018ddr}{{21}{2018}{{Olayan et~al.}}{{Olayan, Ashoor, and Bajic}}}
\bibcite{pahikkala2015toward}{{22}{2015}{{Pahikkala et~al.}}{{Pahikkala, Airola, Pietil{\"a}, Shakyawar, Szwajda, Tang et~al.}}}
\bibcite{pan2016ipminer}{{23}{2016}{{Pan et~al.}}{{Pan, Fan, Yan, and Shen}}}
\bibcite{SNFPy2020}{{24}{2018}{{Ross Markello}}{{}}}
\bibcite{ryu2018deep}{{25}{2018}{{Ryu et~al.}}{{Ryu, Kim, and Lee}}}
\bibcite{seen20121}{{26}{2012}{{Seen}}{{}}}
\bibcite{shi2018tmfuf}{{27}{2018}{{Shi et~al.}}{{Shi, Huang, Li, Lei, Zhang, Dong et~al.}}}
\bibcite{shi2017predicting}{{28}{2017}{{Shi et~al.}}{{Shi, Huang, Li, Lei, Zhang, and Yiu}}}
\bibcite{shi2019detecting}{{29}{2019}{{Shi et~al.}}{{Shi, Mao, Yu, and Yiu}}}
\bibcite{srivastava2014dropout}{{30}{2014}{{Srivastava et~al.}}{{Srivastava, Hinton, Krizhevsky, Sutskever, and Salakhutdinov}}}
\bibcite{tian2017constructing}{{31}{2017}{{Tian et~al.}}{{Tian, Guo, Wang, Xing, Wang, and Zhang}}}
\bibcite{toda2012research}{{32}{2012}{{Toda and Okura}}{{}}}
\bibcite{veith2009comprehensive}{{33}{2009}{{Veith et~al.}}{{Veith, Southall, Huang, James, Fayne, Artemenko et~al.}}}
\bibcite{vilar2014similarity}{{34}{2014}{{Vilar et~al.}}{{Vilar, Uriarte, Santana, Lorberbaum, Hripcsak, Friedman et~al.}}}
\bibcite{wang2014similarity}{{35}{2014}{{Wang et~al.}}{{Wang, Mezlini, Demir, Fiume, Tu, Brudno et~al.}}}
\bibcite{wang2016predicting}{{36}{2016}{{Wang et~al.}}{{Wang, Liu, Xu, Shi, Zhang, Mo et~al.}}}
\bibcite{wienkers2005predicting}{{37}{2005}{{Wienkers and Heath}}{{}}}
\bibcite{wisniowska2016role}{{38}{2016}{{Wi{\'s}niowska and Polak}}{{}}}
\bibcite{yamanishi2008prediction}{{39}{2008}{{Yamanishi et~al.}}{{Yamanishi, Araki, Gutteridge, Honda, and Kanehisa}}}
\bibcite{yu2018predicting}{{40}{2018}{{Yu et~al.}}{{Yu, Mao, Shi, Huang, Chen, Dong et~al.}}}
\bibcite{zhang2015label}{{41}{2015}{{Zhang et~al.}}{{Zhang, Wang, Hu, and Sorrentino}}}
\bibcite{zhang2018manifold}{{42}{2018}{{Zhang et~al.}}{{Zhang, Chen, Li, and Yue}}}
\bibcite{zhang2016drug}{{43}{2016{a}}{{Zhang et~al.}}{{Zhang, Chen, Tu, Liu, and Qu}}}
\bibcite{zhang2016leveraging}{{44}{2016{b}}{{Zhang et~al.}}{{Zhang, Wu, Xu, Wang, Soysal, Li et~al.}}}
\bibcite{zhao2011prediction}{{45}{2011}{{Zhao et~al.}}{{Zhao, Iskar, Zeller, Kuhn, Van~Noort, and Bork}}}
\bibcite{zhou2016simulation}{{46}{2016}{{Zhou et~al.}}{{Zhou, Bui, Sostek, and Al-Huniti}}}
\global\@namedef{@lastpage@}{20}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces  Enter the caption for your figure here. Repeat as necessary for each of your figures\relax }}{20}{figure.caption.23}\protected@file@percent }
\newlabel{fig:1}{{9}{20}{Enter the caption for your figure here. Repeat as necessary for each of your figures\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces This is a figure with sub figures, \textbf  {(A)} is one logo, \textbf  {(B)} is a different logo.\relax }}{20}{figure.caption.24}\protected@file@percent }
\newlabel{fig:2}{{10}{20}{This is a figure with sub figures, \textbf {(A)} is one logo, \textbf {(B)} is a different logo.\relax }{figure.caption.24}{}}
