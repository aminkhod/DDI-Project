\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\global\@namedef{num@address}{2}
\global\@namedef{num@author}{3}
\citation{wienkers2005predicting}
\citation{law2014drugbank}
\citation{leape1995systems}
\citation{businaro2013we}
\citation{karbownik2017pharmacokinetic}
\citation{mulroy2017giant}
\citation{zhao2011prediction}
\citation{veith2009comprehensive}
\citation{huang2007drug}
\citation{zhang2015label}
\gdef\hy@title{Predicting Comperhensive Drug - Drug Interaction via Similarity Network Fusion and Convolutional Neural Networks}
\thanksnewlabel{au1@email}{{khodamoradi1992@gmail.com}{1}}
\thanksnewlabel{au2@email}{{Bahar.levian@gmail.com}{1}}
\thanksnewlabel{au3@email}{{eslahchi.ch@gmail.com}{1}}
\thanksnewlabel{bmc@corref@authorthanks}{{*}{1}}
\@writefile{toc}{\contentsline {section}{Abstract}{1}{section*.1}}
\gdef\hy@fauthor{Mohammad.Amin Khodamoradi}
\gdef\hy@author{Mohammad.Amin Khodamoradi, Bahareh Levian, Changiz Eslahchi}
\gdef\hy@subject{}
\gdef\hy@keywords{Drug-Drug Interaction, Drug Similarity, Drug Similarity Integration, Feature Selection, Recommender System}
\citation{wisniowska2016role}
\citation{zhou2016simulation}
\citation{zhang2015label}
\citation{bui2014novel}
\citation{zhang2016leveraging}
\citation{yamanishi2008prediction}
\citation{vilar2014similarity}
\citation{zhang2015label}
\citation{cheng2014machine}
\citation{pahikkala2015toward}
\citation{vilar2014similarity}
\citation{luo2014ddi}
\citation{cheng2014machine}
\citation{zhang2015label}
\citation{shi2017predicting}
\citation{liu2016dependency}
\citation{ryu2018deep}
\citation{wang2014similarity}
\citation{olayan2018ddr}
\citation{tian2017constructing}
\citation{kim2016understanding}
\citation{wang2016predicting}
\citation{huang2009effect}
\citation{fu2017deep}
\citation{pan2016ipminer}
\citation{koch1981serum}
\citation{shi2018tmfuf}
\citation{yu2018predicting}
\citation{cokol2017efficient}
\citation{shi2018tmfuf}
\citation{yu2018predicting}
\citation{shi2019detecting}
\citation{camacho2018social}
\citation{yu2018predicting}
\citation{zhang2016drug}
\citation{zhang2018manifold}
\citation{wang2014similarity}
\citation{wang2014similarity}
\citation{SNFPy2020}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces SNF processes \cite  {wang2014similarity}: A detailed example of SNF steps. (a) An example representation of chemical structure feature and off-label side effect feature for the same set of drugs. (b) Drug-drug similarity matrices for each feature type. (c) Drug-drug similarity networks, equivalent to the drug-drug data. Nodes represent drugs, and edges represent drug pairwise similarities. (d) Network fusion by SNF iteratively updates each of the networks with information from the other networks, making them more similar with each step. (e) The iterative network fusion results in convergence to the final fused network. Edge color indicates which data type has contributed to the given similarity. }}{6}{figure.1}}
\newlabel{SNF}{{1}{6}{SNF processes \cite {wang2014similarity}: A detailed example of SNF steps. (a) An example representation of chemical structure feature and off-label side effect feature for the same set of drugs. (b) Drug-drug similarity matrices for each feature type. (c) Drug-drug similarity networks, equivalent to the drug-drug data. Nodes represent drugs, and edges represent drug pairwise similarities. (d) Network fusion by SNF iteratively updates each of the networks with information from the other networks, making them more similar with each step. (e) The iterative network fusion results in convergence to the final fused network. Edge color indicates which data type has contributed to the given similarity}{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Matrix header of B}}{6}{figure.2}}
\newlabel{BMatHeader}{{2}{6}{Matrix header of B}{figure.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces The confusion matrix and relevant evaluation index.True Positive (TP): The number of residues classified as interacting correctly, False Positive (FP): The number of residues classified as interacting correctly incorrectly, False Negative (FN): The number of residues classified as non-interacting incorrectly, True Negative (TN): The number of residues classified as non-interacting correctly.}}{7}{table.1}}
\newlabel{confusion_matrix_enh_deg}{{1}{7}{The confusion matrix and relevant evaluation index.True Positive (TP): The number of residues classified as interacting correctly, False Positive (FP): The number of residues classified as interacting correctly incorrectly, False Negative (FN): The number of residues classified as non-interacting incorrectly, True Negative (TN): The number of residues classified as non-interacting correctly}{table.1}{}}
\newlabel{Selecting model}{{}{8}{Selecting model}{section*.14}{}}
\citation{nair2010rectified}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The arrangement of the neural network layers for detecting possible zeros}}{9}{figure.3}}
\newlabel{CNNModel}{{3}{9}{The arrangement of the neural network layers for detecting possible zeros}{figure.3}{}}
\citation{hinton2012deep}
\citation{srivastava2014dropout}
\citation{abadi2016tensorflow}
\citation{chollet2015keras}
\citation{ghosal1997your}
\citation{toda2012research}
\citation{seen20121}
\citation{kingma2014adam}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Learnable parameters of two-class Neural Networks}}{11}{figure.4}}
\newlabel{paramNumber1}{{4}{11}{Learnable parameters of two-class Neural Networks}{figure.4}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Model selection suducode}}{11}{algorithm.1}}
\newlabel{modelSelectionSuducode}{{1}{11}{Selecting model}{algorithm.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces probability density distribution diagram of Degressive and enhancive. In this figure, 0 is the same as the $-1$label, and 1 is the same as $+1$.}}{12}{figure.5}}
\newlabel{DDIProbHist}{{5}{12}{probability density distribution diagram of Degressive and enhancive. In this figure, 0 is the same as the $-1$label, and 1 is the same as $+1$}{figure.5}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Final model selection(SNF-CNN) suducode}}{13}{algorithm.2}}
\newlabel{SNFCNNSuducode}{{2}{13}{Selecting final model}{algorithm.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Arrangement of neural network layers SNF-CNN Predict triple-class interaction. Non-interaction (0), degressive interaction (-1) and enhancive interaction (+1)}}{14}{figure.6}}
\newlabel{Triple_model}{{6}{14}{Arrangement of neural network layers SNF-CNN Predict triple-class interaction. Non-interaction (0), degressive interaction (-1) and enhancive interaction (+1)}{figure.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces The confusion matrix and relevant evaluation index.True Positive (TP): The number of residues classified as interacting correctly, False Positive (FP): The number of residues classified as interacting correctly incorrectly, False Negative (FN): The number of residues classified as non-interacting incorrectly, True Negative (TN): The number of residues classified as non-interacting correctly.}}{15}{table.2}}
\newlabel{confusion_matrix_temp}{{2}{15}{The confusion matrix and relevant evaluation index.True Positive (TP): The number of residues classified as interacting correctly, False Positive (FP): The number of residues classified as interacting correctly incorrectly, False Negative (FN): The number of residues classified as non-interacting incorrectly, True Negative (TN): The number of residues classified as non-interacting correctly}{table.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces \fig@textbf  {Accuracy and loss function for the binary model:} The right figure shows the model's accuracy on training and validation data during 15 epochs, and the left figure shows the loss function values at different epochs.}}{16}{figure.7}}
\newlabel{ModelSelection}{{7}{16}{\textbf {Accuracy and loss function for the binary model:} The right figure shows the model's accuracy on training and validation data during 15 epochs, and the left figure shows the loss function values at different epochs}{figure.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces \fig@textbf  {Accuracy and loss function diagrams for the triple model:} The right figure shows the accuracy of the model on training and validation data during 16 epochs, and the left figure shows the loss function values at different epochs.}}{16}{figure.8}}
\newlabel{lastTripleModel}{{8}{16}{\textbf {Accuracy and loss function diagrams for the triple model:} The right figure shows the accuracy of the model on training and validation data during 16 epochs, and the left figure shows the loss function values at different epochs}{figure.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Interaction type classification report}}{17}{table.3}}
\newlabel{classificatonReport}{{3}{17}{Interaction type classification report}{table.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Three-Classes interaction classification report}}{17}{table.4}}
\newlabel{TripleclassificatonReport}{{4}{17}{Three-Classes interaction classification report}{table.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Results of SNF-CNN algorithm in predicting three-classes based on AUC and AUPR criteria and their confidence interval}}{17}{table.5}}
\newlabel{SNF-CNNresult}{{5}{17}{Results of SNF-CNN algorithm in predicting three-classes based on AUC and AUPR criteria and their confidence interval}{table.5}{}}
\citation{shi2019detecting}
\citation{yu2018predicting}
\citation{shi2018tmfuf}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Comparison of the results of three-classes prediction algorithms based on criteria AUC and AUPR}}{18}{table.6}}
\newlabel{AUCAUPR}{{6}{18}{Comparison of the results of three-classes prediction algorithms based on criteria AUC and AUPR}{table.6}{}}
\bibdata{bmc_article.bib}
\bibcite{wienkers2005predicting}{1}
\bibcite{law2014drugbank}{2}
\bibcite{leape1995systems}{3}
\thanksnewlabel{aff1thanks}{{1}{19}}
\thanksnewlabel{aff2thanks}{{2}{19}}
\bibcite{businaro2013we}{4}
\bibcite{karbownik2017pharmacokinetic}{5}
\bibcite{mulroy2017giant}{6}
\bibcite{zhao2011prediction}{7}
\bibcite{veith2009comprehensive}{8}
\bibcite{huang2007drug}{9}
\bibcite{zhang2015label}{10}
\bibcite{wisniowska2016role}{11}
\bibcite{zhou2016simulation}{12}
\bibcite{bui2014novel}{13}
\bibcite{zhang2016leveraging}{14}
\bibcite{yamanishi2008prediction}{15}
\bibcite{vilar2014similarity}{16}
\bibcite{cheng2014machine}{17}
\bibcite{pahikkala2015toward}{18}
\bibcite{luo2014ddi}{19}
\bibcite{shi2017predicting}{20}
\bibcite{liu2016dependency}{21}
\bibcite{ryu2018deep}{22}
\bibcite{wang2014similarity}{23}
\bibcite{olayan2018ddr}{24}
\bibcite{tian2017constructing}{25}
\bibcite{kim2016understanding}{26}
\bibcite{wang2016predicting}{27}
\bibcite{huang2009effect}{28}
\bibcite{fu2017deep}{29}
\bibcite{pan2016ipminer}{30}
\bibcite{koch1981serum}{31}
\bibcite{shi2018tmfuf}{32}
\bibcite{yu2018predicting}{33}
\bibcite{cokol2017efficient}{34}
\bibcite{shi2019detecting}{35}
\bibcite{camacho2018social}{36}
\bibcite{zhang2016drug}{37}
\bibcite{zhang2018manifold}{38}
\bibcite{SNFPy2020}{39}
\bibcite{nair2010rectified}{40}
\bibcite{hinton2012deep}{41}
\bibcite{srivastava2014dropout}{42}
\bibcite{abadi2016tensorflow}{43}
\bibcite{chollet2015keras}{44}
\bibcite{ghosal1997your}{45}
\bibcite{toda2012research}{46}
\bibcite{seen20121}{47}
\bibcite{kingma2014adam}{48}
\bibstyle{bmc-mathphys}
\newlabel{LastPage}{{}{21}{}{page.21}{}}
\xdef\lastpage@lastpage{21}
\xdef\lastpage@lastpageHy{21}
